{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from opts import parse_opts\n",
    "from mean import get_mean, get_std\n",
    "from spatial_transforms import (\n",
    "    Compose, Normalize, Scale, CenterCrop, CornerCrop, MultiScaleCornerCrop,\n",
    "    MultiScaleRandomCrop, RandomHorizontalFlip, ToTensor)\n",
    "from temporal_transforms import LoopPadding, TemporalRandomCrop\n",
    "from target_transforms import ClassLabel, VideoID\n",
    "from target_transforms import Compose as TargetCompose\n",
    "from dataset import get_training_set, get_validation_set, get_test_set\n",
    "from utils import Logger\n",
    "from train import train_epoch\n",
    "from validation import val_epoch\n",
    "import test\n",
    "import collections\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump, load\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "opt = easydict.EasyDict({\n",
    "    \"result_path\": 'results2',\n",
    "    \"dataset\": 'ucf101-music', # 'ucf101',\n",
    "    \"n_classes\": 9, \n",
    "    \"sample_size\": 112,\n",
    "    \"sample_duration\": 16,\n",
    "    \"initial_scale\": 1.0,\n",
    "    \"n_scales\": 5,\n",
    "    \"scale_step\": 0.84089641525,\n",
    "    \"train_crop\": 'corner',\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"momentum\": 0.9,\n",
    "    \"dampening\": 0.9,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"mean_dataset\": 'activitynet',\n",
    "    \"no_mean_norm\": False,\n",
    "    \"std_norm\": False,\n",
    "    \"nesterov\": False,\n",
    "    \"optimizer\": 'sgd',\n",
    "    \"lr_patience\": 10,\n",
    "    \"batch_size\": 16,\n",
    "    \"n_epochs\": 2,\n",
    "    \"begin_epoch\": 1,\n",
    "    \"n_val_samples\": 3,\n",
    "    \"ft_begin_index\": 5,\n",
    "    \"scale_in_test\": 1.0,\n",
    "    \"crop_position_in_test\": 'c',\n",
    "    \"no_softmax_in_test\": False,\n",
    "    \"no_cuda\": False,\n",
    "    \"n_threads\": 4,\n",
    "    \"checkpoint\": 2,\n",
    "    \"no_hflip\": False,\n",
    "    \"norm_value\": 1,\n",
    "    \"model\": 'resnet',\n",
    "    \"pretained_model_name\": 'resnext-101-kinetics',\n",
    "    \"model_depth\": 101,\n",
    "    \"resnet_shortcut\": 'B',\n",
    "    \"wide_resnet_k\": 2,\n",
    "    \"resnext_cardinality\": 32,\n",
    "    \"manual_seed\": 1,\n",
    "    'test_subset': 'test',\n",
    "})\n",
    "opt.arch = '{}-{}'.format(opt.model, opt.model_depth)\n",
    "opt.root_path = '/data/qq/CSCE689/'\n",
    "opt.video_path = opt.root_path + 'video/UCF-101-jpg/'\n",
    "opt.annotation_path = opt.root_path + 'video/UCF-music-annotation/ucf_binary_music_annotation_correct.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use two gpu devices on the server, you can customize it depending on how many available gpu devices you have\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qq/CSCE689/3D-ResNets-PyTorch/models/resnext.py:121: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import resnext\n",
    "\n",
    "# construct model architecture\n",
    "model = resnext.resnet101(\n",
    "            num_classes=opt.n_classes,\n",
    "            shortcut_type=opt.resnet_shortcut,\n",
    "            cardinality=opt.resnext_cardinality,\n",
    "            sample_size=opt.sample_size,\n",
    "            sample_duration=opt.sample_duration)\n",
    "\n",
    "model = model.cuda()\n",
    "# wrap the current model again in nn.DataParallel / or we can just remove the .module keys.\n",
    "model = nn.DataParallel(model, device_ids=None)\n",
    "\n",
    "# load best weight (we can also refit the model on the combined train-val dataset, \n",
    "# but here we simple load the weight and do the final testing)\n",
    "pretrain = torch.load('./results1/save_50.pth')\n",
    "model.load_state_dict(pretrain['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No/v_BasketballDunk_g01_c02\n",
      "dataset loading [0/1600]\n",
      "dataset loading [1000/1600]\n"
     ]
    }
   ],
   "source": [
    "from datasets.ucf101 import UCF101\n",
    "\n",
    "mean = get_mean(opt.norm_value, dataset='kinetics')\n",
    "std = get_std(opt.norm_value)\n",
    "norm_method = Normalize(mean, [1,1,1])\n",
    "\n",
    "\n",
    "spatial_transform = Compose([\n",
    "    Scale(opt.sample_size),\n",
    "    CornerCrop(opt.sample_size, 'c'),\n",
    "    ToTensor(opt.norm_value), norm_method\n",
    "])\n",
    "\n",
    "temporal_transform = LoopPadding(opt.sample_duration)\n",
    "target_transform = VideoID() # ClassLabel()\n",
    "\n",
    "\n",
    "\n",
    "# get test data\n",
    "test_data = UCF101(\n",
    "    opt.video_path,\n",
    "    opt.annotation_path,\n",
    "    'testing',\n",
    "    0,\n",
    "    spatial_transform=spatial_transform,\n",
    "    temporal_transform=temporal_transform,\n",
    "    target_transform=target_transform,\n",
    "    sample_duration=16)\n",
    "\n",
    "\n",
    "# wrap test data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=opt.n_threads,\n",
    "    pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = ['v_BasketballDunk_g01_c02', \n",
    "            'v_Drumming_g05_c06', \n",
    "            'v_Rafting_g07_c03', \n",
    "            'v_PlayingFlute_g07_c04',\n",
    "            'v_PlayingPiano_g01_c02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvns = np.load(opt.root_path + 'feature_ucf_all/class_names_ucf_test_correct.npy')\n",
    "avi_path = \"/data/qq/CSCE689/video/UCF-101\"\n",
    "clip_duration_dict = {}\n",
    "real_prediction_dict = {}\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "for tvn in examples:\n",
    "    clip = VideoFileClip(os.path.join(avi_path, tvn[2:-8], tvn + \".avi\"))\n",
    "    clip_duration_dict[tvn] = [clip.duration]\n",
    "    print(clip_duration_dict)\n",
    "#     real_prediction_dict[tvn] = test_results['results'][tvn][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_duration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./hw8_results/clip_duration_dict_example.json', 'w') as fp:\n",
    "#     json.dump(clip_duration_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "clf = load('./hw8_results/logistic_ucf.joblib') \n",
    "\n",
    "x_test_1 = np.load(opt.root_path + 'feature_ucf_all/resnext101_avgpool_test.npy')\n",
    "x_test_2 = np.load(opt.root_path + 'feature_ucf_all/resnet50_avgpool_test.npy')\n",
    "x_test = np.concatenate([x_test_1, x_test_2], axis=1)\n",
    "y_test = np.load(opt.root_path + 'feature_ucf_all/class_names_ucf_test_correct.npy')\n",
    "y_pred_test_raw = clf.predict(x_test)\n",
    "y_pred_test_prob_raw = clf.predict_proba(x_test)\n",
    "\n",
    "\n",
    "\n",
    "split_idx = []\n",
    "for idx, y_name in enumerate(y_test):\n",
    "    if idx == 0 or y_name != y_test[idx-1]:\n",
    "        split_idx.append(idx)\n",
    "\n",
    "y_pred_test, y_pred_test_prob, y_pred_test_final = {}, {}, {}\n",
    "for i, split in enumerate(split_idx):\n",
    "    if i < len(split_idx) - 1:\n",
    "        y_pred_test[y_test[split]] = y_pred_test_raw[split:split_idx[i+1]]\n",
    "        y_pred_test_prob[y_test[split]] = y_pred_test_prob_raw[split:split_idx[i+1]]\n",
    "        y_pred_test_final[y_test[split]] = np.argmax(np.mean(y_pred_test_prob_raw[split:split_idx[i+1]], axis=0))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for tvn in examples:\n",
    "    interval = clip_duration_dict[tvn][0]/list(y_test).count(tvn)\n",
    "    x = np.arange(0, clip_duration_dict[tvn][0], interval) + interval\n",
    "    y = y_pred_test_prob[tvn][:, 1]\n",
    "    x = x[:len(y)]\n",
    "    plt.plot(x, y)\n",
    "    plt.ylim([-0.1, 1.1])\n",
    "    plt.xlabel ('time/sec')\n",
    "    plt.ylabel ('pred score for ground truth label')\n",
    "    plt.title(\"Ground Truth Label:  \" + tvn[2:-8]  + \"\\n Model Avg. Predict Score:  \" + str(np.mean(y))) # str(real_prediction_dict[tvn]['score'])\n",
    "    plt.savefig(\"./hw8_results/hw8_examples/\" + tvn, bbox_inches='tight')\n",
    "    plt.close()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "timeTrueLabel = {}\n",
    "for tvn in examples:\n",
    "    interval = clip_duration_dict[tvn][0]/list(y_test).count(tvn)\n",
    "    x = np.arange(0, clip_duration_dict[tvn][0], interval) + interval\n",
    "    y_one_label = y_pred_test_prob[tvn][:, 1]\n",
    "    x = x[:len(y_one_label)]\n",
    "    timeTrueLabel[tvn] = {tvn[2:-8]: [[str(time), str(y_one_label[idx])] for idx, time in enumerate(x)]}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('./hw8_results/hw8_examples/example.json', 'w') as fp:\n",
    "#     json.dump(timeTrueLabel, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract clip duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "tvns = np.load(opt.root_path + 'feature_ucf_all/class_names_ucf_test_correct.npy')\n",
    "avi_path = \"/data/qq/CSCE689/video/UCF-101\"\n",
    "clip_duration_dict = {}\n",
    "\n",
    "n = len(tvns)\n",
    "\n",
    "def my_func(i):\n",
    "    try:\n",
    "        clip = VideoFileClip(os.path.join(avi_path, tvns[i][2:-8], tvns[i] + \".avi\"))\n",
    "        clip_duration_dict[tvns[i]] = [clip.duration]\n",
    "        return clip_duration_dict\n",
    "    except:\n",
    "        print(tvns[i])\n",
    "        return {}\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "my_clip_duration_dict = Parallel(n_jobs=10)(delayed(my_func)(i) for i in range(len(tvns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_clip_duration_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_duration_dict = {}\n",
    "# for d in my_clip_duration_dict:\n",
    "#     clip_duration_dict.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('./hw8_results/clip_duration_dict.json', 'w') as fp:\n",
    "#     json.dump(clip_duration_dict, fp)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hw8_results/clip_duration_dict.json', 'r') as fp:\n",
    "    clip_duration_dict = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clip_duration_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "clf = load('./hw8_results/logistic_ucf.joblib') \n",
    "\n",
    "x_test_1 = np.load(opt.root_path + 'feature_ucf_all/resnext101_avgpool_test.npy')\n",
    "x_test_2 = np.load(opt.root_path + 'feature_ucf_all/resnet50_avgpool_test.npy')\n",
    "x_test = np.concatenate([x_test_1, x_test_2], axis=1)\n",
    "y_test = np.load(opt.root_path + 'feature_ucf_all/class_names_ucf_test_correct.npy')\n",
    "y_pred_test_raw = clf.predict(x_test)\n",
    "y_pred_test_prob_raw = clf.predict_proba(x_test)\n",
    "\n",
    "\n",
    "split_idx = []\n",
    "for idx, y_name in enumerate(y_test):\n",
    "    if idx == 0 or y_name != y_test[idx-1]:\n",
    "        split_idx.append(idx)\n",
    "\n",
    "y_pred_test, y_pred_test_prob, y_pred_test_final = {}, {}, {}\n",
    "for i, split in enumerate(split_idx):\n",
    "    if i < len(split_idx) - 1:\n",
    "        y_pred_test[y_test[split]] = y_pred_test_raw[split:split_idx[i+1]]\n",
    "        y_pred_test_prob[y_test[split]] = y_pred_test_prob_raw[split:split_idx[i+1]]\n",
    "        y_pred_test_final[y_test[split]] = np.argmax(np.mean(y_pred_test_prob_raw[split:split_idx[i+1]], axis=0))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate prediction plot for each video -- HW8 ensemble ResNext-101 + ResNet 50 + logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for tvn in clip_duration_dict:\n",
    "    if tvn in y_pred_test_prob:\n",
    "        interval = clip_duration_dict[tvn][0]/list(y_test).count(tvn)\n",
    "        x = np.arange(0, clip_duration_dict[tvn][0], interval) + interval\n",
    "        y = y_pred_test_prob[tvn][:, 1]\n",
    "        x = x[:len(y)]\n",
    "        plt.plot(x, y)\n",
    "        plt.ylim([-0.1, 1.1])\n",
    "        plt.xlabel ('time/sec')\n",
    "        plt.ylabel ('pred score for ground truth label')\n",
    "        plt.title(\"Ground Truth Label:  \" + tvn[2:-8]  + \"\\n Model Avg. Predict Score:  \" + str(np.mean(y))) # str(real_prediction_dict[tvn]['score'])\n",
    "        plt.savefig(\"./hw8_results/fig_one_label/\" + tvn, bbox_inches='tight')\n",
    "        plt.close()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate json file for each video -- HW8 ensemble ResNext-101 + ResNet 50 + logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "timeTrueLabel = {}\n",
    "for tvn in clip_duration_dict:\n",
    "    if tvn in y_pred_test_prob:\n",
    "        interval = clip_duration_dict[tvn][0]/list(y_test).count(tvn)\n",
    "        x = np.arange(0, clip_duration_dict[tvn][0], interval) + interval\n",
    "        y_idx = np.argmax(y_pred_test_prob[tvn], 1)\n",
    "        x = x[:len(y_one_label)]    \n",
    "        timeTrueLabel[tvn] = {tvn[2:-8]: [[str(time), str(y_one_label[idx])] for idx, time in enumerate(x)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hw8_results/fig_one_label/timeLabel.json', 'w') as fp:\n",
    "    json.dump(timeTrueLabel, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csce689",
   "language": "python",
   "name": "csce689"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
